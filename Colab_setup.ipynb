{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxJOJu4XUIW"
      },
      "source": [
        "### Step 1: Mount the Google Drive\n",
        "\n",
        "Remember to use GPU runtime before mounting your Google Drive. (Runtime --> Change runtime type)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCSU4HrvkVDq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyoSL1U8Xbjh"
      },
      "source": [
        "### Step 2: Open the project directory\n",
        "\n",
        "Replace `Your_Dir` with your own path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gfQ17SmkfOK"
      },
      "outputs": [],
      "source": [
        "cd Your_Dir/emg2qwerty"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTzYfAOEYN4C"
      },
      "source": [
        "### Step 3: Install required packages\n",
        "\n",
        "After installing them, Colab will require you to restart the session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFFKvhs4tAp5"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSoRzGXCfUtz"
      },
      "source": [
        "### Step 4: Start your experiments!\n",
        "\n",
        "- Remember to download and copy the dataset to this directory: `Your_Dir/emg2qwerty/data`.\n",
        "- You may now start your experiments with any scripts! Below are examples of single-user training and testing (greedy decoding).\n",
        "- **There are two ways to track the logs:**\n",
        "  - 1. Keep `--multirun`, and the logs will not be printed here, but they will be saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/submitit_logs/`.\n",
        "  - 2. Comment out `--multirun` and the logs will be printed in this notebook, but they will not be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVuSn4rXhLJa"
      },
      "source": [
        "#### Training\n",
        "\n",
        "- The checkpoints are saved in the folder `logs`, e.g., `logs/2025-02-09/18-24-15/checkpoints/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n84M6KLmkp2i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-10 21:30:06,696][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: true\n",
            "checkpoint: null\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 40\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-10 21:30:06,703][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-10 21:30:06,902][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /workspace/logs/2025-03-10/21-30-06/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/user/.local/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/home/user/.local/lib/python3.10/site-packages/pl_bolts/__init__.py:11: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
            "  if not hasattr(numpy, tp_name):\n",
            "/home/user/.local/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
            "/home/user/.local/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
            "/home/user/.local/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  self.nce_loss = AmdimNCELoss(tclip)\n",
            "/home/user/.local/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
            "  return _target_(*args, **kwargs)\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | model    | Sequential | 2.4 M \n",
            "1 | ctc_loss | CTCLoss    | 0     \n",
            "2 | metrics  | ModuleDict | 0     \n",
            "----------------------------------------\n",
            "2.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "2.4 M     Total params\n",
            "9.564     Total estimated model params size (MB)\n",
            "Epoch 0:  94%|████████████▎| 120/127 [00:36<00:02,  3.33it/s, loss=161, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 0:  95%|████████████▍| 121/127 [00:36<00:01,  3.27it/s, loss=161, v_num=0]\u001b[A\n",
            "Epoch 0:  96%|████████████▍| 122/127 [00:37<00:01,  3.29it/s, loss=161, v_num=0]\u001b[A\n",
            "Epoch 0:  97%|████████████▌| 123/127 [00:37<00:01,  3.32it/s, loss=161, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▋| 124/127 [00:37<00:00,  3.34it/s, loss=161, v_num=0]\u001b[A\n",
            "Epoch 0:  98%|████████████▊| 125/127 [00:37<00:00,  3.32it/s, loss=161, v_num=0]\u001b[A\n",
            "Epoch 0:  99%|████████████▉| 126/127 [00:37<00:00,  3.35it/s, loss=161, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 127/127 [00:37<00:00,  3.37it/s, loss=161, v_num=0]\u001b[A\n",
            "Epoch 0: 100%|█████████████| 127/127 [00:37<00:00,  3.37it/s, loss=161, v_num=0]\u001b[AEpoch 0, global step 120: 'val/CER' reached 121.86531 (best 121.86531), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=0-step=120.ckpt' as top 1\n",
            "Epoch 1:  94%|███████████▎| 120/127 [00:34<00:01,  3.52it/s, loss=3.66, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 1:  95%|███████████▍| 121/127 [00:35<00:01,  3.45it/s, loss=3.66, v_num=0]\u001b[A\n",
            "Epoch 1:  96%|███████████▌| 122/127 [00:35<00:01,  3.47it/s, loss=3.66, v_num=0]\u001b[A\n",
            "Epoch 1:  97%|███████████▌| 123/127 [00:35<00:01,  3.49it/s, loss=3.66, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▋| 124/127 [00:35<00:00,  3.51it/s, loss=3.66, v_num=0]\u001b[A\n",
            "Epoch 1:  98%|███████████▊| 125/127 [00:35<00:00,  3.51it/s, loss=3.66, v_num=0]\u001b[A\n",
            "Epoch 1:  99%|███████████▉| 126/127 [00:35<00:00,  3.53it/s, loss=3.66, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 127/127 [00:35<00:00,  3.55it/s, loss=3.66, v_num=0]\u001b[A\n",
            "Epoch 1: 100%|████████████| 127/127 [00:35<00:00,  3.55it/s, loss=3.66, v_num=0]Epoch 1, global step 240: 'val/CER' reached 100.00000 (best 100.00000), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=1-step=240.ckpt' as top 1\n",
            "Epoch 2:  94%|████████████▎| 120/127 [00:32<00:01,  3.67it/s, loss=3.4, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 2:  95%|████████████▍| 121/127 [00:33<00:01,  3.61it/s, loss=3.4, v_num=0]\u001b[A\n",
            "Epoch 2:  96%|████████████▍| 122/127 [00:33<00:01,  3.63it/s, loss=3.4, v_num=0]\u001b[A\n",
            "Epoch 2:  97%|████████████▌| 123/127 [00:33<00:01,  3.66it/s, loss=3.4, v_num=0]\u001b[A\n",
            "Epoch 2:  98%|████████████▋| 124/127 [00:33<00:00,  3.68it/s, loss=3.4, v_num=0]\u001b[A\n",
            "Epoch 2:  98%|████████████▊| 125/127 [00:34<00:00,  3.66it/s, loss=3.4, v_num=0]\u001b[A\n",
            "Epoch 2:  99%|████████████▉| 126/127 [00:34<00:00,  3.69it/s, loss=3.4, v_num=0]\u001b[A\n",
            "Epoch 2: 100%|█████████████| 127/127 [00:34<00:00,  3.71it/s, loss=3.4, v_num=0]\u001b[A\n",
            "Epoch 2: 100%|█████████████| 127/127 [00:34<00:00,  3.71it/s, loss=3.4, v_num=0]Epoch 2, global step 360: 'val/CER' was not in top 1\n",
            "Epoch 3:  94%|███████████▎| 120/127 [00:32<00:01,  3.68it/s, loss=3.37, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 3:  95%|███████████▍| 121/127 [00:33<00:01,  3.61it/s, loss=3.37, v_num=0]\u001b[A\n",
            "Epoch 3:  96%|███████████▌| 122/127 [00:33<00:01,  3.63it/s, loss=3.37, v_num=0]\u001b[A\n",
            "Epoch 3:  97%|███████████▌| 123/127 [00:33<00:01,  3.65it/s, loss=3.37, v_num=0]\u001b[A\n",
            "Epoch 3:  98%|███████████▋| 124/127 [00:33<00:00,  3.67it/s, loss=3.37, v_num=0]\u001b[A\n",
            "Epoch 3:  98%|███████████▊| 125/127 [00:34<00:00,  3.66it/s, loss=3.37, v_num=0]\u001b[A\n",
            "Epoch 3:  99%|███████████▉| 126/127 [00:34<00:00,  3.68it/s, loss=3.37, v_num=0]\u001b[A\n",
            "Epoch 3: 100%|████████████| 127/127 [00:34<00:00,  3.70it/s, loss=3.37, v_num=0]\u001b[A\n",
            "Epoch 3: 100%|████████████| 127/127 [00:34<00:00,  3.70it/s, loss=3.37, v_num=0]Epoch 3, global step 480: 'val/CER' was not in top 1\n",
            "Epoch 4:  94%|███████████▎| 120/127 [00:31<00:01,  3.77it/s, loss=3.31, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 4:  95%|███████████▍| 121/127 [00:32<00:01,  3.70it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 4:  96%|███████████▌| 122/127 [00:32<00:01,  3.72it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 4:  97%|███████████▌| 123/127 [00:32<00:01,  3.74it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 4:  98%|███████████▋| 124/127 [00:32<00:00,  3.76it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 4:  98%|███████████▊| 125/127 [00:33<00:00,  3.76it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 4:  99%|███████████▉| 126/127 [00:33<00:00,  3.78it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 4: 100%|████████████| 127/127 [00:33<00:00,  3.80it/s, loss=3.31, v_num=0]\u001b[A\n",
            "Epoch 4: 100%|████████████| 127/127 [00:33<00:00,  3.80it/s, loss=3.31, v_num=0]Epoch 4, global step 600: 'val/CER' was not in top 1\n",
            "Epoch 5:  94%|████████████▎| 120/127 [00:32<00:01,  3.73it/s, loss=3.3, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 5:  95%|████████████▍| 121/127 [00:33<00:01,  3.65it/s, loss=3.3, v_num=0]\u001b[A\n",
            "Epoch 5:  96%|████████████▍| 122/127 [00:33<00:01,  3.67it/s, loss=3.3, v_num=0]\u001b[A\n",
            "Epoch 5:  97%|████████████▌| 123/127 [00:33<00:01,  3.69it/s, loss=3.3, v_num=0]\u001b[A\n",
            "Epoch 5:  98%|████████████▋| 124/127 [00:33<00:00,  3.71it/s, loss=3.3, v_num=0]\u001b[A\n",
            "Epoch 5:  98%|████████████▊| 125/127 [00:33<00:00,  3.70it/s, loss=3.3, v_num=0]\u001b[A\n",
            "Epoch 5:  99%|████████████▉| 126/127 [00:33<00:00,  3.72it/s, loss=3.3, v_num=0]\u001b[A\n",
            "Epoch 5: 100%|█████████████| 127/127 [00:33<00:00,  3.75it/s, loss=3.3, v_num=0]\u001b[A\n",
            "Epoch 5: 100%|█████████████| 127/127 [00:33<00:00,  3.75it/s, loss=3.3, v_num=0]Epoch 5, global step 720: 'val/CER' was not in top 1\n",
            "Epoch 6:  94%|███████████▎| 120/127 [00:31<00:01,  3.77it/s, loss=3.22, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 6:  95%|███████████▍| 121/127 [00:32<00:01,  3.69it/s, loss=3.22, v_num=0]\u001b[A\n",
            "Epoch 6:  96%|███████████▌| 122/127 [00:32<00:01,  3.71it/s, loss=3.22, v_num=0]\u001b[A\n",
            "Epoch 6:  97%|███████████▌| 123/127 [00:32<00:01,  3.73it/s, loss=3.22, v_num=0]\u001b[A\n",
            "Epoch 6:  98%|███████████▋| 124/127 [00:33<00:00,  3.75it/s, loss=3.22, v_num=0]\u001b[A\n",
            "Epoch 6:  98%|███████████▊| 125/127 [00:33<00:00,  3.74it/s, loss=3.22, v_num=0]\u001b[A\n",
            "Epoch 6:  99%|███████████▉| 126/127 [00:33<00:00,  3.76it/s, loss=3.22, v_num=0]\u001b[A\n",
            "Epoch 6: 100%|████████████| 127/127 [00:33<00:00,  3.78it/s, loss=3.22, v_num=0]\u001b[A\n",
            "Epoch 6: 100%|████████████| 127/127 [00:33<00:00,  3.78it/s, loss=3.22, v_num=0]Epoch 6, global step 840: 'val/CER' was not in top 1\n",
            "Epoch 7:  94%|███████████▎| 120/127 [00:32<00:01,  3.74it/s, loss=3.12, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 7:  95%|███████████▍| 121/127 [00:32<00:01,  3.67it/s, loss=3.12, v_num=0]\u001b[A\n",
            "Epoch 7:  96%|███████████▌| 122/127 [00:33<00:01,  3.69it/s, loss=3.12, v_num=0]\u001b[A\n",
            "Epoch 7:  97%|███████████▌| 123/127 [00:33<00:01,  3.71it/s, loss=3.12, v_num=0]\u001b[A\n",
            "Epoch 7:  98%|███████████▋| 124/127 [00:33<00:00,  3.73it/s, loss=3.12, v_num=0]\u001b[A\n",
            "Epoch 7:  98%|███████████▊| 125/127 [00:33<00:00,  3.72it/s, loss=3.12, v_num=0]\u001b[A\n",
            "Epoch 7:  99%|███████████▉| 126/127 [00:33<00:00,  3.74it/s, loss=3.12, v_num=0]\u001b[A\n",
            "Epoch 7: 100%|████████████| 127/127 [00:33<00:00,  3.76it/s, loss=3.12, v_num=0]\u001b[A\n",
            "Epoch 7: 100%|████████████| 127/127 [00:33<00:00,  3.76it/s, loss=3.12, v_num=0]Epoch 7, global step 960: 'val/CER' was not in top 1\n",
            "Epoch 8:  94%|███████████▎| 120/127 [00:32<00:01,  3.73it/s, loss=3.04, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 8:  95%|███████████▍| 121/127 [00:33<00:01,  3.65it/s, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 8:  96%|███████████▌| 122/127 [00:33<00:01,  3.67it/s, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 8:  97%|███████████▌| 123/127 [00:33<00:01,  3.69it/s, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 8:  98%|███████████▋| 124/127 [00:33<00:00,  3.71it/s, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 8:  98%|███████████▊| 125/127 [00:33<00:00,  3.69it/s, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 8:  99%|███████████▉| 126/127 [00:33<00:00,  3.71it/s, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 8: 100%|████████████| 127/127 [00:33<00:00,  3.74it/s, loss=3.04, v_num=0]\u001b[A\n",
            "Epoch 8: 100%|████████████| 127/127 [00:33<00:00,  3.74it/s, loss=3.04, v_num=0]Epoch 8, global step 1080: 'val/CER' was not in top 1\n",
            "Epoch 9:  94%|███████████▎| 120/127 [00:32<00:01,  3.73it/s, loss=2.96, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 9:  95%|███████████▍| 121/127 [00:33<00:01,  3.66it/s, loss=2.96, v_num=0]\u001b[A\n",
            "Epoch 9:  96%|███████████▌| 122/127 [00:33<00:01,  3.68it/s, loss=2.96, v_num=0]\u001b[A\n",
            "Epoch 9:  97%|███████████▌| 123/127 [00:33<00:01,  3.70it/s, loss=2.96, v_num=0]\u001b[A\n",
            "Epoch 9:  98%|███████████▋| 124/127 [00:33<00:00,  3.72it/s, loss=2.96, v_num=0]\u001b[A\n",
            "Epoch 9:  98%|███████████▊| 125/127 [00:33<00:00,  3.71it/s, loss=2.96, v_num=0]\u001b[A\n",
            "Epoch 9:  99%|███████████▉| 126/127 [00:33<00:00,  3.73it/s, loss=2.96, v_num=0]\u001b[A\n",
            "Epoch 9: 100%|████████████| 127/127 [00:33<00:00,  3.76it/s, loss=2.96, v_num=0]\u001b[A\n",
            "Epoch 9: 100%|████████████| 127/127 [00:33<00:00,  3.76it/s, loss=2.96, v_num=0]\u001b[AEpoch 9, global step 1200: 'val/CER' was not in top 1\n",
            "Epoch 10:  94%|██████████▍| 120/127 [00:31<00:01,  3.77it/s, loss=2.81, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 10:  95%|██████████▍| 121/127 [00:32<00:01,  3.69it/s, loss=2.81, v_num=0]\u001b[A\n",
            "Epoch 10:  96%|██████████▌| 122/127 [00:32<00:01,  3.71it/s, loss=2.81, v_num=0]\u001b[A\n",
            "Epoch 10:  97%|██████████▋| 123/127 [00:32<00:01,  3.73it/s, loss=2.81, v_num=0]\u001b[A\n",
            "Epoch 10:  98%|██████████▋| 124/127 [00:33<00:00,  3.75it/s, loss=2.81, v_num=0]\u001b[A\n",
            "Epoch 10:  98%|██████████▊| 125/127 [00:33<00:00,  3.75it/s, loss=2.81, v_num=0]\u001b[A\n",
            "Epoch 10:  99%|██████████▉| 126/127 [00:33<00:00,  3.77it/s, loss=2.81, v_num=0]\u001b[A\n",
            "Epoch 10: 100%|███████████| 127/127 [00:33<00:00,  3.79it/s, loss=2.81, v_num=0]\u001b[A\n",
            "Epoch 10: 100%|███████████| 127/127 [00:33<00:00,  3.79it/s, loss=2.81, v_num=0]Epoch 10, global step 1320: 'val/CER' was not in top 1\n",
            "Epoch 11:  94%|██████████▍| 120/127 [00:31<00:01,  3.78it/s, loss=2.62, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 11:  95%|██████████▍| 121/127 [00:32<00:01,  3.70it/s, loss=2.62, v_num=0]\u001b[A\n",
            "Epoch 11:  96%|██████████▌| 122/127 [00:32<00:01,  3.73it/s, loss=2.62, v_num=0]\u001b[A\n",
            "Epoch 11:  97%|██████████▋| 123/127 [00:32<00:01,  3.75it/s, loss=2.62, v_num=0]\u001b[A\n",
            "Epoch 11:  98%|██████████▋| 124/127 [00:32<00:00,  3.77it/s, loss=2.62, v_num=0]\u001b[A\n",
            "Epoch 11:  98%|██████████▊| 125/127 [00:33<00:00,  3.75it/s, loss=2.62, v_num=0]\u001b[A\n",
            "Epoch 11:  99%|██████████▉| 126/127 [00:33<00:00,  3.78it/s, loss=2.62, v_num=0]\u001b[A\n",
            "Epoch 11: 100%|███████████| 127/127 [00:33<00:00,  3.80it/s, loss=2.62, v_num=0]\u001b[A\n",
            "Epoch 11: 100%|███████████| 127/127 [00:33<00:00,  3.80it/s, loss=2.62, v_num=0]Epoch 11, global step 1440: 'val/CER' reached 96.45547 (best 96.45547), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=11-step=1440.ckpt' as top 1\n",
            "Epoch 12:  94%|███████████▎| 120/127 [00:33<00:01,  3.63it/s, loss=2.3, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 12:  95%|███████████▍| 121/127 [00:33<00:01,  3.57it/s, loss=2.3, v_num=0]\u001b[A\n",
            "Epoch 12:  96%|███████████▌| 122/127 [00:34<00:01,  3.58it/s, loss=2.3, v_num=0]\u001b[A\n",
            "Epoch 12:  97%|███████████▌| 123/127 [00:34<00:01,  3.61it/s, loss=2.3, v_num=0]\u001b[A\n",
            "Epoch 12:  98%|███████████▋| 124/127 [00:34<00:00,  3.63it/s, loss=2.3, v_num=0]\u001b[A\n",
            "Epoch 12:  98%|███████████▊| 125/127 [00:34<00:00,  3.61it/s, loss=2.3, v_num=0]\u001b[A\n",
            "Epoch 12:  99%|███████████▉| 126/127 [00:34<00:00,  3.63it/s, loss=2.3, v_num=0]\u001b[A\n",
            "Epoch 12: 100%|████████████| 127/127 [00:34<00:00,  3.66it/s, loss=2.3, v_num=0]\u001b[A\n",
            "Epoch 12: 100%|████████████| 127/127 [00:34<00:00,  3.66it/s, loss=2.3, v_num=0]Epoch 12, global step 1560: 'val/CER' reached 82.63181 (best 82.63181), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=12-step=1560.ckpt' as top 1\n",
            "Epoch 13:  94%|██████████▍| 120/127 [00:31<00:01,  3.75it/s, loss=1.92, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 13:  95%|██████████▍| 121/127 [00:32<00:01,  3.67it/s, loss=1.92, v_num=0]\u001b[A\n",
            "Epoch 13:  96%|██████████▌| 122/127 [00:33<00:01,  3.69it/s, loss=1.92, v_num=0]\u001b[A\n",
            "Epoch 13:  97%|██████████▋| 123/127 [00:33<00:01,  3.71it/s, loss=1.92, v_num=0]\u001b[A\n",
            "Epoch 13:  98%|██████████▋| 124/127 [00:33<00:00,  3.73it/s, loss=1.92, v_num=0]\u001b[A\n",
            "Epoch 13:  98%|██████████▊| 125/127 [00:33<00:00,  3.72it/s, loss=1.92, v_num=0]\u001b[A\n",
            "Epoch 13:  99%|██████████▉| 126/127 [00:33<00:00,  3.74it/s, loss=1.92, v_num=0]\u001b[A\n",
            "Epoch 13: 100%|███████████| 127/127 [00:33<00:00,  3.77it/s, loss=1.92, v_num=0]\u001b[A\n",
            "Epoch 13: 100%|███████████| 127/127 [00:33<00:00,  3.77it/s, loss=1.92, v_num=0]Epoch 13, global step 1680: 'val/CER' reached 59.65884 (best 59.65884), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=13-step=1680.ckpt' as top 1\n",
            "Epoch 14:  94%|██████████▍| 120/127 [00:32<00:01,  3.64it/s, loss=1.74, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 14:  95%|██████████▍| 121/127 [00:34<00:01,  3.54it/s, loss=1.74, v_num=0]\u001b[A\n",
            "Epoch 14:  96%|██████████▌| 122/127 [00:34<00:01,  3.56it/s, loss=1.74, v_num=0]\u001b[A\n",
            "Epoch 14:  97%|██████████▋| 123/127 [00:34<00:01,  3.58it/s, loss=1.74, v_num=0]\u001b[A\n",
            "Epoch 14:  98%|██████████▋| 124/127 [00:34<00:00,  3.60it/s, loss=1.74, v_num=0]\u001b[A\n",
            "Epoch 14:  98%|██████████▊| 125/127 [00:34<00:00,  3.60it/s, loss=1.74, v_num=0]\u001b[A\n",
            "Epoch 14:  99%|██████████▉| 126/127 [00:34<00:00,  3.62it/s, loss=1.74, v_num=0]\u001b[A\n",
            "Epoch 14: 100%|███████████| 127/127 [00:34<00:00,  3.64it/s, loss=1.74, v_num=0]\u001b[A\n",
            "Epoch 14: 100%|███████████| 127/127 [00:34<00:00,  3.64it/s, loss=1.74, v_num=0]Epoch 14, global step 1800: 'val/CER' reached 51.48427 (best 51.48427), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=14-step=1800.ckpt' as top 1\n",
            "Epoch 15:  94%|██████████▍| 120/127 [00:32<00:01,  3.65it/s, loss=1.58, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 15:  95%|██████████▍| 121/127 [00:33<00:01,  3.58it/s, loss=1.58, v_num=0]\u001b[A\n",
            "Epoch 15:  96%|██████████▌| 122/127 [00:33<00:01,  3.60it/s, loss=1.58, v_num=0]\u001b[A\n",
            "Epoch 15:  97%|██████████▋| 123/127 [00:34<00:01,  3.62it/s, loss=1.58, v_num=0]\u001b[A\n",
            "Epoch 15:  98%|██████████▋| 124/127 [00:34<00:00,  3.64it/s, loss=1.58, v_num=0]\u001b[A\n",
            "Epoch 15:  98%|██████████▊| 125/127 [00:34<00:00,  3.63it/s, loss=1.58, v_num=0]\u001b[A\n",
            "Epoch 15:  99%|██████████▉| 126/127 [00:34<00:00,  3.65it/s, loss=1.58, v_num=0]\u001b[A\n",
            "Epoch 15: 100%|███████████| 127/127 [00:34<00:00,  3.67it/s, loss=1.58, v_num=0]\u001b[A\n",
            "Epoch 15: 100%|███████████| 127/127 [00:34<00:00,  3.67it/s, loss=1.58, v_num=0]Epoch 15, global step 1920: 'val/CER' reached 48.44927 (best 48.44927), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=15-step=1920.ckpt' as top 1\n",
            "Epoch 16:  94%|██████████▍| 120/127 [00:31<00:01,  3.76it/s, loss=1.46, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 16:  95%|██████████▍| 121/127 [00:32<00:01,  3.68it/s, loss=1.46, v_num=0]\u001b[A\n",
            "Epoch 16:  96%|██████████▌| 122/127 [00:33<00:01,  3.70it/s, loss=1.46, v_num=0]\u001b[A\n",
            "Epoch 16:  97%|██████████▋| 123/127 [00:33<00:01,  3.72it/s, loss=1.46, v_num=0]\u001b[A\n",
            "Epoch 16:  98%|██████████▋| 124/127 [00:33<00:00,  3.74it/s, loss=1.46, v_num=0]\u001b[A\n",
            "Epoch 16:  98%|██████████▊| 125/127 [00:33<00:00,  3.73it/s, loss=1.46, v_num=0]\u001b[A\n",
            "Epoch 16:  99%|██████████▉| 126/127 [00:33<00:00,  3.76it/s, loss=1.46, v_num=0]\u001b[A\n",
            "Epoch 16: 100%|███████████| 127/127 [00:33<00:00,  3.78it/s, loss=1.46, v_num=0]\u001b[A\n",
            "Epoch 16: 100%|███████████| 127/127 [00:33<00:00,  3.78it/s, loss=1.46, v_num=0]Epoch 16, global step 2040: 'val/CER' reached 42.33496 (best 42.33496), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=16-step=2040.ckpt' as top 1\n",
            "Epoch 17:  94%|██████████▍| 120/127 [00:31<00:01,  3.78it/s, loss=1.32, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 17:  95%|██████████▍| 121/127 [00:32<00:01,  3.69it/s, loss=1.32, v_num=0]\u001b[A\n",
            "Epoch 17:  96%|██████████▌| 122/127 [00:32<00:01,  3.71it/s, loss=1.32, v_num=0]\u001b[A\n",
            "Epoch 17:  97%|██████████▋| 123/127 [00:32<00:01,  3.73it/s, loss=1.32, v_num=0]\u001b[A\n",
            "Epoch 17:  98%|██████████▋| 124/127 [00:33<00:00,  3.75it/s, loss=1.32, v_num=0]\u001b[A\n",
            "Epoch 17:  98%|██████████▊| 125/127 [00:33<00:00,  3.75it/s, loss=1.32, v_num=0]\u001b[A\n",
            "Epoch 17:  99%|██████████▉| 126/127 [00:33<00:00,  3.77it/s, loss=1.32, v_num=0]\u001b[A\n",
            "Epoch 17: 100%|███████████| 127/127 [00:33<00:00,  3.79it/s, loss=1.32, v_num=0]\u001b[A\n",
            "Epoch 17: 100%|███████████| 127/127 [00:33<00:00,  3.79it/s, loss=1.32, v_num=0]Epoch 17, global step 2160: 'val/CER' reached 37.99291 (best 37.99291), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=17-step=2160.ckpt' as top 1\n",
            "Epoch 18:  94%|██████████▍| 120/127 [00:32<00:01,  3.73it/s, loss=1.27, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 18:  95%|██████████▍| 121/127 [00:33<00:01,  3.65it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 18:  96%|██████████▌| 122/127 [00:33<00:01,  3.67it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 18:  97%|██████████▋| 123/127 [00:33<00:01,  3.69it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 18:  98%|██████████▋| 124/127 [00:33<00:00,  3.71it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 18:  98%|██████████▊| 125/127 [00:33<00:00,  3.71it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 18:  99%|██████████▉| 126/127 [00:33<00:00,  3.73it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 18: 100%|███████████| 127/127 [00:33<00:00,  3.75it/s, loss=1.27, v_num=0]\u001b[A\n",
            "Epoch 18: 100%|███████████| 127/127 [00:33<00:00,  3.75it/s, loss=1.27, v_num=0]Epoch 18, global step 2280: 'val/CER' was not in top 1\n",
            "Epoch 19:  94%|███████████▎| 120/127 [00:32<00:01,  3.70it/s, loss=1.2, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 19:  95%|███████████▍| 121/127 [00:33<00:01,  3.63it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 19:  96%|███████████▌| 122/127 [00:33<00:01,  3.65it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 19:  97%|███████████▌| 123/127 [00:33<00:01,  3.67it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 19:  98%|███████████▋| 124/127 [00:33<00:00,  3.69it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 19:  98%|███████████▊| 125/127 [00:33<00:00,  3.68it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 19:  99%|███████████▉| 126/127 [00:34<00:00,  3.70it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 19: 100%|████████████| 127/127 [00:34<00:00,  3.73it/s, loss=1.2, v_num=0]\u001b[A\n",
            "Epoch 19: 100%|████████████| 127/127 [00:34<00:00,  3.73it/s, loss=1.2, v_num=0]Epoch 19, global step 2400: 'val/CER' reached 34.55915 (best 34.55915), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=19-step=2400.ckpt' as top 1\n",
            "Epoch 20:  94%|██████████▍| 120/127 [00:32<00:01,  3.71it/s, loss=1.11, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 20:  95%|██████████▍| 121/127 [00:33<00:01,  3.63it/s, loss=1.11, v_num=0]\u001b[A\n",
            "Epoch 20:  96%|██████████▌| 122/127 [00:33<00:01,  3.65it/s, loss=1.11, v_num=0]\u001b[A\n",
            "Epoch 20:  97%|██████████▋| 123/127 [00:33<00:01,  3.67it/s, loss=1.11, v_num=0]\u001b[A\n",
            "Epoch 20:  98%|██████████▋| 124/127 [00:33<00:00,  3.69it/s, loss=1.11, v_num=0]\u001b[A\n",
            "Epoch 20:  98%|██████████▊| 125/127 [00:33<00:00,  3.68it/s, loss=1.11, v_num=0]\u001b[A\n",
            "Epoch 20:  99%|██████████▉| 126/127 [00:34<00:00,  3.70it/s, loss=1.11, v_num=0]\u001b[A\n",
            "Epoch 20: 100%|███████████| 127/127 [00:34<00:00,  3.72it/s, loss=1.11, v_num=0]\u001b[A\n",
            "Epoch 20: 100%|███████████| 127/127 [00:34<00:00,  3.72it/s, loss=1.11, v_num=0]Epoch 20, global step 2520: 'val/CER' was not in top 1\n",
            "Epoch 21:  94%|███████████▎| 120/127 [00:32<00:01,  3.72it/s, loss=1.1, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 21:  95%|███████████▍| 121/127 [00:33<00:01,  3.65it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 21:  96%|███████████▌| 122/127 [00:33<00:01,  3.67it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 21:  97%|███████████▌| 123/127 [00:33<00:01,  3.69it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 21:  98%|███████████▋| 124/127 [00:33<00:00,  3.71it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 21:  98%|███████████▊| 125/127 [00:33<00:00,  3.69it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 21:  99%|███████████▉| 126/127 [00:33<00:00,  3.71it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 21: 100%|████████████| 127/127 [00:33<00:00,  3.74it/s, loss=1.1, v_num=0]\u001b[A\n",
            "Epoch 21: 100%|████████████| 127/127 [00:33<00:00,  3.74it/s, loss=1.1, v_num=0]Epoch 21, global step 2640: 'val/CER' reached 30.92601 (best 30.92601), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=21-step=2640.ckpt' as top 1\n",
            "Epoch 22:  94%|██████████▍| 120/127 [00:32<00:01,  3.72it/s, loss=1.02, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 22:  95%|██████████▍| 121/127 [00:33<00:01,  3.65it/s, loss=1.02, v_num=0]\u001b[A\n",
            "Epoch 22:  96%|██████████▌| 122/127 [00:33<00:01,  3.67it/s, loss=1.02, v_num=0]\u001b[A\n",
            "Epoch 22:  97%|██████████▋| 123/127 [00:33<00:01,  3.69it/s, loss=1.02, v_num=0]\u001b[A\n",
            "Epoch 22:  98%|██████████▋| 124/127 [00:33<00:00,  3.71it/s, loss=1.02, v_num=0]\u001b[A\n",
            "Epoch 22:  98%|██████████▊| 125/127 [00:33<00:00,  3.70it/s, loss=1.02, v_num=0]\u001b[A\n",
            "Epoch 22:  99%|██████████▉| 126/127 [00:33<00:00,  3.72it/s, loss=1.02, v_num=0]\u001b[A\n",
            "Epoch 22: 100%|███████████| 127/127 [00:33<00:00,  3.74it/s, loss=1.02, v_num=0]\u001b[A\n",
            "Epoch 22: 100%|███████████| 127/127 [00:33<00:00,  3.74it/s, loss=1.02, v_num=0]Epoch 22, global step 2760: 'val/CER' was not in top 1\n",
            "Epoch 23:  94%|█████████▍| 120/127 [00:32<00:01,  3.70it/s, loss=0.977, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 23:  95%|█████████▌| 121/127 [00:33<00:01,  3.62it/s, loss=0.977, v_num=0]\u001b[A\n",
            "Epoch 23:  96%|█████████▌| 122/127 [00:33<00:01,  3.64it/s, loss=0.977, v_num=0]\u001b[A\n",
            "Epoch 23:  97%|█████████▋| 123/127 [00:33<00:01,  3.66it/s, loss=0.977, v_num=0]\u001b[A\n",
            "Epoch 23:  98%|█████████▊| 124/127 [00:33<00:00,  3.68it/s, loss=0.977, v_num=0]\u001b[A\n",
            "Epoch 23:  98%|█████████▊| 125/127 [00:33<00:00,  3.68it/s, loss=0.977, v_num=0]\u001b[A\n",
            "Epoch 23:  99%|█████████▉| 126/127 [00:34<00:00,  3.70it/s, loss=0.977, v_num=0]\u001b[A\n",
            "Epoch 23: 100%|██████████| 127/127 [00:34<00:00,  3.73it/s, loss=0.977, v_num=0]\u001b[A\n",
            "Epoch 23: 100%|██████████| 127/127 [00:34<00:00,  3.72it/s, loss=0.977, v_num=0]Epoch 23, global step 2880: 'val/CER' reached 29.22020 (best 29.22020), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=23-step=2880.ckpt' as top 1\n",
            "Epoch 24:  94%|█████████▍| 120/127 [00:32<00:01,  3.70it/s, loss=0.957, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 24:  95%|█████████▌| 121/127 [00:33<00:01,  3.62it/s, loss=0.957, v_num=0]\u001b[A\n",
            "Epoch 24:  96%|█████████▌| 122/127 [00:33<00:01,  3.64it/s, loss=0.957, v_num=0]\u001b[A\n",
            "Epoch 24:  97%|█████████▋| 123/127 [00:33<00:01,  3.66it/s, loss=0.957, v_num=0]\u001b[A\n",
            "Epoch 24:  98%|█████████▊| 124/127 [00:33<00:00,  3.68it/s, loss=0.957, v_num=0]\u001b[A\n",
            "Epoch 24:  98%|█████████▊| 125/127 [00:33<00:00,  3.68it/s, loss=0.957, v_num=0]\u001b[A\n",
            "Epoch 24:  99%|█████████▉| 126/127 [00:34<00:00,  3.70it/s, loss=0.957, v_num=0]\u001b[A\n",
            "Epoch 24: 100%|██████████| 127/127 [00:34<00:00,  3.72it/s, loss=0.957, v_num=0]\u001b[A\n",
            "Epoch 24: 100%|██████████| 127/127 [00:34<00:00,  3.72it/s, loss=0.957, v_num=0]Epoch 24, global step 3000: 'val/CER' was not in top 1\n",
            "Epoch 25:  94%|█████████▍| 120/127 [00:32<00:01,  3.67it/s, loss=0.932, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 25:  95%|█████████▌| 121/127 [00:33<00:01,  3.59it/s, loss=0.932, v_num=0]\u001b[A\n",
            "Epoch 25:  96%|█████████▌| 122/127 [00:33<00:01,  3.61it/s, loss=0.932, v_num=0]\u001b[A\n",
            "Epoch 25:  97%|█████████▋| 123/127 [00:33<00:01,  3.63it/s, loss=0.932, v_num=0]\u001b[A\n",
            "Epoch 25:  98%|█████████▊| 124/127 [00:33<00:00,  3.65it/s, loss=0.932, v_num=0]\u001b[A\n",
            "Epoch 25:  98%|█████████▊| 125/127 [00:34<00:00,  3.65it/s, loss=0.932, v_num=0]\u001b[A\n",
            "Epoch 25:  99%|█████████▉| 126/127 [00:34<00:00,  3.67it/s, loss=0.932, v_num=0]\u001b[A\n",
            "Epoch 25: 100%|██████████| 127/127 [00:34<00:00,  3.69it/s, loss=0.932, v_num=0]\u001b[A\n",
            "Epoch 25: 100%|██████████| 127/127 [00:34<00:00,  3.69it/s, loss=0.932, v_num=0]Epoch 25, global step 3120: 'val/CER' reached 27.00487 (best 27.00487), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=25-step=3120.ckpt' as top 1\n",
            "Epoch 26:  94%|█████████▍| 120/127 [00:32<00:01,  3.72it/s, loss=0.897, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 26:  95%|█████████▌| 121/127 [00:33<00:01,  3.65it/s, loss=0.897, v_num=0]\u001b[A\n",
            "Epoch 26:  96%|█████████▌| 122/127 [00:33<00:01,  3.67it/s, loss=0.897, v_num=0]\u001b[A\n",
            "Epoch 26:  97%|█████████▋| 123/127 [00:33<00:01,  3.69it/s, loss=0.897, v_num=0]\u001b[A\n",
            "Epoch 26:  98%|█████████▊| 124/127 [00:33<00:00,  3.71it/s, loss=0.897, v_num=0]\u001b[A\n",
            "Epoch 26:  98%|█████████▊| 125/127 [00:33<00:00,  3.70it/s, loss=0.897, v_num=0]\u001b[A\n",
            "Epoch 26:  99%|█████████▉| 126/127 [00:33<00:00,  3.72it/s, loss=0.897, v_num=0]\u001b[A\n",
            "Epoch 26: 100%|██████████| 127/127 [00:33<00:00,  3.74it/s, loss=0.897, v_num=0]\u001b[A\n",
            "Epoch 26: 100%|██████████| 127/127 [00:33<00:00,  3.74it/s, loss=0.897, v_num=0]Epoch 26, global step 3240: 'val/CER' reached 26.87195 (best 26.87195), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=26-step=3240.ckpt' as top 1\n",
            "Epoch 27:  94%|█████████▍| 120/127 [00:32<00:01,  3.70it/s, loss=0.854, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 27:  95%|█████████▌| 121/127 [00:33<00:01,  3.63it/s, loss=0.854, v_num=0]\u001b[A\n",
            "Epoch 27:  96%|█████████▌| 122/127 [00:33<00:01,  3.65it/s, loss=0.854, v_num=0]\u001b[A\n",
            "Epoch 27:  97%|█████████▋| 123/127 [00:33<00:01,  3.67it/s, loss=0.854, v_num=0]\u001b[A\n",
            "Epoch 27:  98%|█████████▊| 124/127 [00:33<00:00,  3.69it/s, loss=0.854, v_num=0]\u001b[A\n",
            "Epoch 27:  98%|█████████▊| 125/127 [00:33<00:00,  3.68it/s, loss=0.854, v_num=0]\u001b[A\n",
            "Epoch 27:  99%|█████████▉| 126/127 [00:34<00:00,  3.70it/s, loss=0.854, v_num=0]\u001b[A\n",
            "Epoch 27: 100%|██████████| 127/127 [00:34<00:00,  3.72it/s, loss=0.854, v_num=0]\u001b[A\n",
            "Epoch 27: 100%|██████████| 127/127 [00:34<00:00,  3.72it/s, loss=0.854, v_num=0]Epoch 27, global step 3360: 'val/CER' reached 26.18520 (best 26.18520), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=27-step=3360.ckpt' as top 1\n",
            "Epoch 28:  94%|█████████▍| 120/127 [00:34<00:02,  3.46it/s, loss=0.838, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 28:  95%|█████████▌| 121/127 [00:35<00:01,  3.40it/s, loss=0.838, v_num=0]\u001b[A\n",
            "Epoch 28:  96%|█████████▌| 122/127 [00:35<00:01,  3.41it/s, loss=0.838, v_num=0]\u001b[A\n",
            "Epoch 28:  97%|█████████▋| 123/127 [00:35<00:01,  3.43it/s, loss=0.838, v_num=0]\u001b[A\n",
            "Epoch 28:  98%|█████████▊| 124/127 [00:35<00:00,  3.45it/s, loss=0.838, v_num=0]\u001b[A\n",
            "Epoch 28:  98%|█████████▊| 125/127 [00:36<00:00,  3.45it/s, loss=0.838, v_num=0]\u001b[A\n",
            "Epoch 28:  99%|█████████▉| 126/127 [00:36<00:00,  3.47it/s, loss=0.838, v_num=0]\u001b[A\n",
            "Epoch 28: 100%|██████████| 127/127 [00:36<00:00,  3.49it/s, loss=0.838, v_num=0]\u001b[A\n",
            "Epoch 28: 100%|██████████| 127/127 [00:36<00:00,  3.49it/s, loss=0.838, v_num=0]Epoch 28, global step 3480: 'val/CER' reached 26.05228 (best 26.05228), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=28-step=3480.ckpt' as top 1\n",
            "Epoch 29:  94%|█████████▍| 120/127 [00:35<00:02,  3.38it/s, loss=0.798, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 29:  95%|█████████▌| 121/127 [00:36<00:01,  3.31it/s, loss=0.798, v_num=0]\u001b[A\n",
            "Epoch 29:  96%|█████████▌| 122/127 [00:36<00:01,  3.33it/s, loss=0.798, v_num=0]\u001b[A\n",
            "Epoch 29:  97%|█████████▋| 123/127 [00:36<00:01,  3.35it/s, loss=0.798, v_num=0]\u001b[A\n",
            "Epoch 29:  98%|█████████▊| 124/127 [00:36<00:00,  3.37it/s, loss=0.798, v_num=0]\u001b[A\n",
            "Epoch 29:  98%|█████████▊| 125/127 [00:37<00:00,  3.36it/s, loss=0.798, v_num=0]\u001b[A\n",
            "Epoch 29:  99%|█████████▉| 126/127 [00:37<00:00,  3.38it/s, loss=0.798, v_num=0]\u001b[A\n",
            "Epoch 29: 100%|██████████| 127/127 [00:37<00:00,  3.40it/s, loss=0.798, v_num=0]\u001b[A\n",
            "Epoch 29: 100%|██████████| 127/127 [00:37<00:00,  3.40it/s, loss=0.798, v_num=0]Epoch 29, global step 3600: 'val/CER' reached 25.36553 (best 25.36553), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=29-step=3600.ckpt' as top 1\n",
            "Epoch 30:  94%|█████████▍| 120/127 [00:35<00:02,  3.40it/s, loss=0.769, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 30:  95%|█████████▌| 121/127 [00:36<00:01,  3.33it/s, loss=0.769, v_num=0]\u001b[A\n",
            "Epoch 30:  96%|█████████▌| 122/127 [00:36<00:01,  3.35it/s, loss=0.769, v_num=0]\u001b[A\n",
            "Epoch 30:  97%|█████████▋| 123/127 [00:36<00:01,  3.37it/s, loss=0.769, v_num=0]\u001b[A\n",
            "Epoch 30:  98%|█████████▊| 124/127 [00:36<00:00,  3.39it/s, loss=0.769, v_num=0]\u001b[A\n",
            "Epoch 30:  98%|█████████▊| 125/127 [00:37<00:00,  3.38it/s, loss=0.769, v_num=0]\u001b[A\n",
            "Epoch 30:  99%|█████████▉| 126/127 [00:37<00:00,  3.40it/s, loss=0.769, v_num=0]\u001b[A\n",
            "Epoch 30: 100%|██████████| 127/127 [00:37<00:00,  3.42it/s, loss=0.769, v_num=0]\u001b[A\n",
            "Epoch 30: 100%|██████████| 127/127 [00:37<00:00,  3.42it/s, loss=0.769, v_num=0]Epoch 30, global step 3720: 'val/CER' reached 23.90341 (best 23.90341), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=30-step=3720.ckpt' as top 1\n",
            "Epoch 31:  94%|█████████▍| 120/127 [00:37<00:02,  3.22it/s, loss=0.767, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 31:  95%|█████████▌| 121/127 [00:38<00:01,  3.16it/s, loss=0.767, v_num=0]\u001b[A\n",
            "Epoch 31:  96%|█████████▌| 122/127 [00:38<00:01,  3.17it/s, loss=0.767, v_num=0]\u001b[A\n",
            "Epoch 31:  97%|█████████▋| 123/127 [00:38<00:01,  3.19it/s, loss=0.767, v_num=0]\u001b[A\n",
            "Epoch 31:  98%|█████████▊| 124/127 [00:38<00:00,  3.21it/s, loss=0.767, v_num=0]\u001b[A\n",
            "Epoch 31:  98%|█████████▊| 125/127 [00:38<00:00,  3.21it/s, loss=0.767, v_num=0]\u001b[A\n",
            "Epoch 31:  99%|█████████▉| 126/127 [00:39<00:00,  3.23it/s, loss=0.767, v_num=0]\u001b[A\n",
            "Epoch 31: 100%|██████████| 127/127 [00:39<00:00,  3.25it/s, loss=0.767, v_num=0]\u001b[A\n",
            "Epoch 31: 100%|██████████| 127/127 [00:39<00:00,  3.25it/s, loss=0.767, v_num=0]\u001b[AEpoch 31, global step 3840: 'val/CER' was not in top 1\n",
            "Epoch 32:  94%|█████████▍| 120/127 [00:35<00:02,  3.40it/s, loss=0.732, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 32:  95%|█████████▌| 121/127 [00:36<00:01,  3.32it/s, loss=0.732, v_num=0]\u001b[A\n",
            "Epoch 32:  96%|█████████▌| 122/127 [00:36<00:01,  3.33it/s, loss=0.732, v_num=0]\u001b[A\n",
            "Epoch 32:  97%|█████████▋| 123/127 [00:36<00:01,  3.36it/s, loss=0.732, v_num=0]\u001b[A\n",
            "Epoch 32:  98%|█████████▊| 124/127 [00:36<00:00,  3.38it/s, loss=0.732, v_num=0]\u001b[A\n",
            "Epoch 32:  98%|█████████▊| 125/127 [00:37<00:00,  3.37it/s, loss=0.732, v_num=0]\u001b[A\n",
            "Epoch 32:  99%|█████████▉| 126/127 [00:37<00:00,  3.39it/s, loss=0.732, v_num=0]\u001b[A\n",
            "Epoch 32: 100%|██████████| 127/127 [00:37<00:00,  3.41it/s, loss=0.732, v_num=0]Epoch 32, global step 3960: 'val/CER' reached 22.86221 (best 22.86221), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=32-step=3960.ckpt' as top 1\n",
            "Epoch 33:  94%|█████████▍| 120/127 [00:37<00:02,  3.23it/s, loss=0.715, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 33:  95%|█████████▌| 121/127 [00:38<00:01,  3.18it/s, loss=0.715, v_num=0]\u001b[A\n",
            "Epoch 33:  96%|█████████▌| 122/127 [00:38<00:01,  3.19it/s, loss=0.715, v_num=0]\u001b[A\n",
            "Epoch 33:  97%|█████████▋| 123/127 [00:38<00:01,  3.21it/s, loss=0.715, v_num=0]\u001b[A\n",
            "Epoch 33:  98%|█████████▊| 124/127 [00:38<00:00,  3.23it/s, loss=0.715, v_num=0]\u001b[A\n",
            "Epoch 33:  98%|█████████▊| 125/127 [00:38<00:00,  3.22it/s, loss=0.715, v_num=0]\u001b[A\n",
            "Epoch 33:  99%|█████████▉| 126/127 [00:38<00:00,  3.24it/s, loss=0.715, v_num=0]\u001b[A\n",
            "Epoch 33: 100%|██████████| 127/127 [00:38<00:00,  3.26it/s, loss=0.715, v_num=0]\u001b[A\n",
            "Epoch 33: 100%|██████████| 127/127 [00:38<00:00,  3.26it/s, loss=0.715, v_num=0]Epoch 33, global step 4080: 'val/CER' reached 22.84005 (best 22.84005), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=33-step=4080.ckpt' as top 1\n",
            "Epoch 34:  94%|█████████▍| 120/127 [00:36<00:02,  3.32it/s, loss=0.723, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 34:  95%|█████████▌| 121/127 [00:37<00:01,  3.26it/s, loss=0.723, v_num=0]\u001b[A\n",
            "Epoch 34:  96%|█████████▌| 122/127 [00:37<00:01,  3.28it/s, loss=0.723, v_num=0]\u001b[A\n",
            "Epoch 34:  97%|█████████▋| 123/127 [00:37<00:01,  3.30it/s, loss=0.723, v_num=0]\u001b[A\n",
            "Epoch 34:  98%|█████████▊| 124/127 [00:37<00:00,  3.32it/s, loss=0.723, v_num=0]\u001b[A\n",
            "Epoch 34:  98%|█████████▊| 125/127 [00:37<00:00,  3.31it/s, loss=0.723, v_num=0]\u001b[A\n",
            "Epoch 34:  99%|█████████▉| 126/127 [00:37<00:00,  3.33it/s, loss=0.723, v_num=0]\u001b[A\n",
            "Epoch 34: 100%|██████████| 127/127 [00:37<00:00,  3.35it/s, loss=0.723, v_num=0]\u001b[A\n",
            "Epoch 34: 100%|██████████| 127/127 [00:37<00:00,  3.35it/s, loss=0.723, v_num=0]Epoch 34, global step 4200: 'val/CER' reached 22.55206 (best 22.55206), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=34-step=4200.ckpt' as top 1\n",
            "Epoch 35:  94%|█████████▍| 120/127 [00:35<00:02,  3.42it/s, loss=0.703, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 35:  95%|█████████▌| 121/127 [00:36<00:01,  3.36it/s, loss=0.703, v_num=0]\u001b[A\n",
            "Epoch 35:  96%|█████████▌| 122/127 [00:36<00:01,  3.38it/s, loss=0.703, v_num=0]\u001b[A\n",
            "Epoch 35:  97%|█████████▋| 123/127 [00:36<00:01,  3.40it/s, loss=0.703, v_num=0]\u001b[A\n",
            "Epoch 35:  98%|█████████▊| 124/127 [00:36<00:00,  3.42it/s, loss=0.703, v_num=0]\u001b[A\n",
            "Epoch 35:  98%|█████████▊| 125/127 [00:36<00:00,  3.41it/s, loss=0.703, v_num=0]\u001b[A\n",
            "Epoch 35:  99%|█████████▉| 126/127 [00:36<00:00,  3.43it/s, loss=0.703, v_num=0]\u001b[A\n",
            "Epoch 35: 100%|██████████| 127/127 [00:36<00:00,  3.45it/s, loss=0.703, v_num=0]\u001b[A\n",
            "Epoch 35: 100%|██████████| 127/127 [00:36<00:00,  3.45it/s, loss=0.703, v_num=0]Epoch 35, global step 4320: 'val/CER' was not in top 1\n",
            "Epoch 36:  94%|█████████▍| 120/127 [00:33<00:01,  3.56it/s, loss=0.678, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 36:  95%|█████████▌| 121/127 [00:34<00:01,  3.50it/s, loss=0.678, v_num=0]\u001b[A\n",
            "Epoch 36:  96%|█████████▌| 122/127 [00:34<00:01,  3.52it/s, loss=0.678, v_num=0]\u001b[A\n",
            "Epoch 36:  97%|█████████▋| 123/127 [00:34<00:01,  3.54it/s, loss=0.678, v_num=0]\u001b[A\n",
            "Epoch 36:  98%|█████████▊| 124/127 [00:34<00:00,  3.56it/s, loss=0.678, v_num=0]\u001b[A\n",
            "Epoch 36:  98%|█████████▊| 125/127 [00:35<00:00,  3.55it/s, loss=0.678, v_num=0]\u001b[A\n",
            "Epoch 36:  99%|█████████▉| 126/127 [00:35<00:00,  3.57it/s, loss=0.678, v_num=0]\u001b[A\n",
            "Epoch 36: 100%|██████████| 127/127 [00:35<00:00,  3.59it/s, loss=0.678, v_num=0]\u001b[A\n",
            "Epoch 36: 100%|██████████| 127/127 [00:35<00:00,  3.59it/s, loss=0.678, v_num=0]Epoch 36, global step 4440: 'val/CER' reached 22.26407 (best 22.26407), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=36-step=4440.ckpt' as top 1\n",
            "Epoch 37:  94%|███████████▎| 120/127 [00:34<00:01,  3.50it/s, loss=0.7, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 37:  95%|███████████▍| 121/127 [00:35<00:01,  3.44it/s, loss=0.7, v_num=0]\u001b[A\n",
            "Epoch 37:  96%|███████████▌| 122/127 [00:35<00:01,  3.46it/s, loss=0.7, v_num=0]\u001b[A\n",
            "Epoch 37:  97%|███████████▌| 123/127 [00:35<00:01,  3.47it/s, loss=0.7, v_num=0]\u001b[A\n",
            "Epoch 37:  98%|███████████▋| 124/127 [00:35<00:00,  3.49it/s, loss=0.7, v_num=0]\u001b[A\n",
            "Epoch 37:  98%|███████████▊| 125/127 [00:35<00:00,  3.48it/s, loss=0.7, v_num=0]\u001b[A\n",
            "Epoch 37:  99%|███████████▉| 126/127 [00:36<00:00,  3.50it/s, loss=0.7, v_num=0]\u001b[A\n",
            "Epoch 37: 100%|████████████| 127/127 [00:36<00:00,  3.52it/s, loss=0.7, v_num=0]\u001b[A\n",
            "Epoch 37: 100%|████████████| 127/127 [00:36<00:00,  3.52it/s, loss=0.7, v_num=0]Epoch 37, global step 4560: 'val/CER' reached 21.82100 (best 21.82100), saving model to '/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=37-step=4560.ckpt' as top 1\n",
            "Epoch 38:  94%|█████████▍| 120/127 [00:35<00:02,  3.43it/s, loss=0.673, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 38:  95%|█████████▌| 121/127 [00:36<00:01,  3.36it/s, loss=0.673, v_num=0]\u001b[A\n",
            "Epoch 38:  96%|█████████▌| 122/127 [00:36<00:01,  3.38it/s, loss=0.673, v_num=0]\u001b[A\n",
            "Epoch 38:  97%|█████████▋| 123/127 [00:36<00:01,  3.39it/s, loss=0.673, v_num=0]\u001b[A\n",
            "Epoch 38:  98%|█████████▊| 124/127 [00:36<00:00,  3.41it/s, loss=0.673, v_num=0]\u001b[A\n",
            "Epoch 38:  98%|█████████▊| 125/127 [00:36<00:00,  3.40it/s, loss=0.673, v_num=0]\u001b[A\n",
            "Epoch 38:  99%|█████████▉| 126/127 [00:36<00:00,  3.42it/s, loss=0.673, v_num=0]\u001b[A\n",
            "Epoch 38: 100%|██████████| 127/127 [00:36<00:00,  3.44it/s, loss=0.673, v_num=0]\u001b[A\n",
            "Epoch 38: 100%|██████████| 127/127 [00:36<00:00,  3.44it/s, loss=0.673, v_num=0]Epoch 38, global step 4680: 'val/CER' was not in top 1\n",
            "Epoch 39:  94%|█████████▍| 120/127 [00:36<00:02,  3.33it/s, loss=0.688, v_num=0]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0%|                                         | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|                            | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch 39:  95%|█████████▌| 121/127 [00:36<00:01,  3.27it/s, loss=0.688, v_num=0]\u001b[A\n",
            "Epoch 39:  96%|█████████▌| 122/127 [00:37<00:01,  3.29it/s, loss=0.688, v_num=0]\u001b[A\n",
            "Epoch 39:  97%|█████████▋| 123/127 [00:37<00:01,  3.32it/s, loss=0.688, v_num=0]\u001b[A\n",
            "Epoch 39:  98%|█████████▊| 124/127 [00:37<00:00,  3.34it/s, loss=0.688, v_num=0]\u001b[A\n",
            "Epoch 39:  98%|█████████▊| 125/127 [00:37<00:00,  3.33it/s, loss=0.688, v_num=0]\u001b[A\n",
            "Epoch 39:  99%|█████████▉| 126/127 [00:37<00:00,  3.35it/s, loss=0.688, v_num=0]\u001b[A\n",
            "Epoch 39: 100%|██████████| 127/127 [00:37<00:00,  3.37it/s, loss=0.688, v_num=0]\u001b[A\n",
            "Epoch 39: 100%|██████████| 127/127 [00:37<00:00,  3.37it/s, loss=0.688, v_num=0]Epoch 39, global step 4800: 'val/CER' was not in top 1\n",
            "`Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "Epoch 39: 100%|██████████| 127/127 [00:37<00:00,  3.36it/s, loss=0.688, v_num=0]\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:00<00:00,  9.30it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER            21.821001052856445\n",
            "         val/DER            2.4590163230895996\n",
            "         val/IER             6.490917205810547\n",
            "         val/SER            12.871068000793457\n",
            "        val/loss            0.7066081166267395\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing: 0it [00:00, ?it/s]Error executing job with overrides: ['user=single_user', 'trainer.accelerator=gpu', 'trainer.devices=1', 'trainer.max_epochs=40']\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/workspace/emg2qwerty/train.py\", line 129, in <module>\n",
            "    main()\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/main.py\", line 94, in decorated_main\n",
            "    _run_hydra(\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
            "    _run_app(\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
            "    run_and_report(\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
            "    raise ex\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
            "    return func()\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
            "    lambda: hydra.run(\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
            "    _ = ret.return_value\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
            "    raise self._return_value\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
            "    ret.return_value = task_function(task_cfg)\n",
            "  File \"/workspace/emg2qwerty/train.py\", line 117, in main\n",
            "    test_metrics = trainer.test(module, datamodule)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 780, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 829, in _test_impl\n",
            "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1098, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1174, in _run_stage\n",
            "    return self._run_evaluate()\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_evaluate\n",
            "    eval_loop_results = self._evaluation_loop.run()\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 152, in advance\n",
            "    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 121, in advance\n",
            "    batch = next(data_fetcher)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py\", line 184, in __next__\n",
            "    return self.fetching_function()\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py\", line 265, in fetching_function\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/home/user/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py\", line 280, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1346, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1372, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/_utils.py\", line 705, in reraise\n",
            "    raise exception\n",
            "RuntimeError: Caught RuntimeError in pin memory thread for device 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 37, in do_one_step\n",
            "    data = pin_memory(data, device)\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in pin_memory\n",
            "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 68, in <dictcomp>\n",
            "    clone.update({k: pin_memory(sample, device) for k, sample in data.items()})\n",
            "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 58, in pin_memory\n",
            "    return data.pin_memory(device)\n",
            "RuntimeError: CUDA error: out of memory\n",
            "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
            "\n",
            "\n",
            "Testing: 0it [00:04, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "# Single-user training\n",
        "!PYTORCH_ENABLE_MPS_FALLBACK=1 \\\n",
        "  HYDRA_FULL_ERROR=1 \\\n",
        "  python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  trainer.accelerator=gpu trainer.devices=1 \\\n",
        "  trainer.max_epochs=40"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGANotiwhngl"
      },
      "source": [
        "#### Testing:\n",
        "\n",
        "- Replace `Your_Path_to_Checkpoint` with your checkpoint path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p68aDt-8pmGj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-03-10 21:59:40,231][__main__][INFO] - \n",
            "Config:\n",
            "user: single_user\n",
            "dataset:\n",
            "  train:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622765527-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622681518-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622863166-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627003020-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626916256-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627004019-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622885888-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622679967-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622764398-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626917264-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622889105-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-03-1622766673-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622861066-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-22-1627001995-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-06-05-1622884635-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  - user: 89335547\n",
            "    session: 2021-07-21-1626915176-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  val:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-04-1622862148-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  test:\n",
            "  - user: 89335547\n",
            "    session: 2021-06-02-1622682789-keystrokes-dca-study@1-0efbe614-9ae6-4131-9192-4398359b4f5f\n",
            "  root: ${hydra:runtime.cwd}/data\n",
            "to_tensor:\n",
            "  _target_: emg2qwerty.transforms.ToTensor\n",
            "  fields:\n",
            "  - emg_left\n",
            "  - emg_right\n",
            "band_rotation:\n",
            "  _target_: emg2qwerty.transforms.ForEach\n",
            "  transform:\n",
            "    _target_: emg2qwerty.transforms.RandomBandRotation\n",
            "    offsets:\n",
            "    - -1\n",
            "    - 0\n",
            "    - 1\n",
            "temporal_jitter:\n",
            "  _target_: emg2qwerty.transforms.TemporalAlignmentJitter\n",
            "  max_offset: 120\n",
            "logspec:\n",
            "  _target_: emg2qwerty.transforms.LogSpectrogram\n",
            "  n_fft: 64\n",
            "  hop_length: 16\n",
            "specaug:\n",
            "  _target_: emg2qwerty.transforms.SpecAugment\n",
            "  n_time_masks: 3\n",
            "  time_mask_param: 25\n",
            "  n_freq_masks: 2\n",
            "  freq_mask_param: 4\n",
            "transforms:\n",
            "  train:\n",
            "  - ${to_tensor}\n",
            "  - ${band_rotation}\n",
            "  - ${temporal_jitter}\n",
            "  - ${logspec}\n",
            "  - ${specaug}\n",
            "  val:\n",
            "  - ${to_tensor}\n",
            "  - ${logspec}\n",
            "  test: ${transforms.val}\n",
            "module:\n",
            "  _target_: emg2qwerty.lightning.TDSConvCTCModule\n",
            "  in_features: 528\n",
            "  mlp_features:\n",
            "  - 384\n",
            "  block_channels:\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  - 24\n",
            "  kernel_width: 32\n",
            "datamodule:\n",
            "  _target_: emg2qwerty.lightning.WindowedEMGDataModule\n",
            "  window_length: 8000\n",
            "  padding:\n",
            "  - 1800\n",
            "  - 200\n",
            "optimizer:\n",
            "  _target_: torch.optim.Adam\n",
            "  lr: 0.001\n",
            "lr_scheduler:\n",
            "  scheduler:\n",
            "    _target_: pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR\n",
            "    warmup_epochs: 10\n",
            "    max_epochs: ${trainer.max_epochs}\n",
            "    warmup_start_lr: 1.0e-08\n",
            "    eta_min: 1.0e-06\n",
            "  interval: epoch\n",
            "decoder:\n",
            "  _target_: emg2qwerty.decoder.CTCGreedyDecoder\n",
            "seed: 1501\n",
            "batch_size: 32\n",
            "num_workers: 4\n",
            "train: false\n",
            "checkpoint: /workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=37-step=4560.ckpt\n",
            "monitor_metric: val/CER\n",
            "monitor_mode: min\n",
            "trainer:\n",
            "  accelerator: gpu\n",
            "  devices: 1\n",
            "  num_nodes: 1\n",
            "  max_epochs: 150\n",
            "  default_root_dir: ${hydra:runtime.output_dir}\n",
            "callbacks:\n",
            "- _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
            "- _target_: pytorch_lightning.callbacks.ModelCheckpoint\n",
            "  dirpath: ${hydra:runtime.output_dir}/checkpoints\n",
            "  monitor: ${monitor_metric}\n",
            "  mode: ${monitor_mode}\n",
            "  save_last: true\n",
            "  verbose: true\n",
            "\n",
            "Global seed set to 1501\n",
            "[2025-03-10 21:59:40,235][__main__][INFO] - Instantiating LightningModule {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}\n",
            "[2025-03-10 21:59:40,309][__main__][INFO] - Loading module from checkpoint /workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=37-step=4560.ckpt\n",
            "[2025-03-10 21:59:40,487][__main__][INFO] - Instantiating LightningDataModule {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /workspace/logs/2025-03-10/21-59-40/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Validation DataLoader 0: 100%|████████████████████| 7/7 [00:00<00:00, 11.32it/s]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "     Validate metric           DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "         val/CER            21.821001052856445\n",
            "         val/DER            2.4590163230895996\n",
            "         val/IER             6.490917205810547\n",
            "         val/SER            12.871068000793457\n",
            "        val/loss            0.7066081166267395\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Testing DataLoader 0: 100%|███████████████████████| 1/1 [00:06<00:00,  6.08s/it]\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "        test/CER            23.384483337402344\n",
            "        test/DER             2.63669753074646\n",
            "        test/IER             4.603414535522461\n",
            "        test/SER             16.14436912536621\n",
            "        test/loss            0.726340651512146\n",
            "────────────────────────────────────────────────────────────────────────────────\n",
            "{'val_metrics': [{'val/loss': 0.7066081166267395,\n",
            "                  'val/CER': 21.821001052856445,\n",
            "                  'val/IER': 6.490917205810547,\n",
            "                  'val/DER': 2.4590163230895996,\n",
            "                  'val/SER': 12.871068000793457}],\n",
            " 'test_metrics': [{'test/loss': 0.726340651512146,\n",
            "                   'test/CER': 23.384483337402344,\n",
            "                   'test/IER': 4.603414535522461,\n",
            "                   'test/DER': 2.63669753074646,\n",
            "                   'test/SER': 16.14436912536621}],\n",
            " 'best_checkpoint': ''}\n"
          ]
        }
      ],
      "source": [
        "# Single-user testing\n",
        "!PYTORCH_ENABLE_MPS_FALLBACK=1 \\\n",
        "  HYDRA_FULL_ERROR=1 \\\n",
        "  python -m emg2qwerty.train \\\n",
        "  user=\"single_user\" \\\n",
        "  checkpoint=\"'/workspace/logs/2025-03-10/21-30-06/checkpoints/epoch=37-step=4560.ckpt'\" \\\n",
        "  train=False trainer.accelerator=gpu \\\n",
        "  decoder=ctc_greedy \\\n",
        "  hydra.launcher.mem_gb=64 \\\n",
        "  # --multirun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tensorboard --logdir='/Users/jonathonyoungquist/Local/ECE_C147/Project/emg2qwerty/logs/2025-03-01/11-14-51/job0_trainer.devices=1,trainer.max_epochs=40,user=single_user/lightning_logs/version_0/'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
